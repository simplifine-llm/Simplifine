{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOkySQHV/4UdgZPvyOgwZDq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "11192f5f2a0f419abc73a0b19b778bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_354f48b02ffe42189cde2221ad1410b4",
              "IPY_MODEL_3075ac4886474981aa4ff5346031d59e",
              "IPY_MODEL_6b35e9ce3e684dd3aefbc0b413a7f4b5"
            ],
            "layout": "IPY_MODEL_4576c6f8758b4ce0a20e1becfe1f5d41"
          }
        },
        "354f48b02ffe42189cde2221ad1410b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b61bd3786bef452b938611ca8f8425ad",
            "placeholder": "​",
            "style": "IPY_MODEL_f81226a58e544f7283f7d8e22e4dffe6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3075ac4886474981aa4ff5346031d59e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60a4dc08f4134011910fe5d2740cf821",
            "max": 396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b034da9e06be4f6f9f21a4f01f1c85d2",
            "value": 396
          }
        },
        "6b35e9ce3e684dd3aefbc0b413a7f4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e740156fc704c8fa4046f1c42ba513e",
            "placeholder": "​",
            "style": "IPY_MODEL_1add250a0ca34f2b83a4cf773d44f433",
            "value": " 396/396 [00:00&lt;00:00, 30.9kB/s]"
          }
        },
        "4576c6f8758b4ce0a20e1becfe1f5d41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b61bd3786bef452b938611ca8f8425ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f81226a58e544f7283f7d8e22e4dffe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60a4dc08f4134011910fe5d2740cf821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b034da9e06be4f6f9f21a4f01f1c85d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e740156fc704c8fa4046f1c42ba513e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1add250a0ca34f2b83a4cf773d44f433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58cd9e66a03e45f5bf5054a9905948b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bff58105f90145869fbf6c5a49399c31",
              "IPY_MODEL_d741ff2bc9914811a2cf2016d61b5ab0",
              "IPY_MODEL_12b642c93fd34118b6d57ae38b6290ec"
            ],
            "layout": "IPY_MODEL_c50ed3d16c4a4d10a35be8eb80a2198d"
          }
        },
        "bff58105f90145869fbf6c5a49399c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4837b95ac97d40c1a5bab60d72eb34d6",
            "placeholder": "​",
            "style": "IPY_MODEL_8a9ce28a49d84d03b03c9c15e3a126dc",
            "value": "tokenizer.json: 100%"
          }
        },
        "d741ff2bc9914811a2cf2016d61b5ab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15b34d19cb534e2da4bdb7ce63f26267",
            "max": 2113710,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4db10b1cd4094a78bf59abbbe862602c",
            "value": 2113710
          }
        },
        "12b642c93fd34118b6d57ae38b6290ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b340b7510add48ab8cf55f340afc2c15",
            "placeholder": "​",
            "style": "IPY_MODEL_c6a85afeffd441a1812d685a132124a8",
            "value": " 2.11M/2.11M [00:01&lt;00:00, 1.90MB/s]"
          }
        },
        "c50ed3d16c4a4d10a35be8eb80a2198d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4837b95ac97d40c1a5bab60d72eb34d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a9ce28a49d84d03b03c9c15e3a126dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15b34d19cb534e2da4bdb7ce63f26267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4db10b1cd4094a78bf59abbbe862602c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b340b7510add48ab8cf55f340afc2c15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6a85afeffd441a1812d685a132124a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70b470dd561c4589b056931f26e8a9bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ae7713c09f24fe1a3f91cfdd22fbff9",
              "IPY_MODEL_5dc27afea8344173a2130b6553eb5be8",
              "IPY_MODEL_6fcfc1af885c41a987454c5ee34b945a"
            ],
            "layout": "IPY_MODEL_7ca30f56c4c541ab97a17920facb482d"
          }
        },
        "3ae7713c09f24fe1a3f91cfdd22fbff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af05a5aecb2a4046ac63d7c02b751ea0",
            "placeholder": "​",
            "style": "IPY_MODEL_e46110a64b6345488b19560229db62ce",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "5dc27afea8344173a2130b6553eb5be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ce1b7d5a796496784c72c263e9f3181",
            "max": 99,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_757d171f689b43a5afe610e65123904f",
            "value": 99
          }
        },
        "6fcfc1af885c41a987454c5ee34b945a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57081f159ab44b4ebbc25d805cb3daa4",
            "placeholder": "​",
            "style": "IPY_MODEL_45bd88ec92094662b0b735e9c62c3938",
            "value": " 99.0/99.0 [00:00&lt;00:00, 8.87kB/s]"
          }
        },
        "7ca30f56c4c541ab97a17920facb482d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af05a5aecb2a4046ac63d7c02b751ea0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e46110a64b6345488b19560229db62ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ce1b7d5a796496784c72c263e9f3181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "757d171f689b43a5afe610e65123904f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57081f159ab44b4ebbc25d805cb3daa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45bd88ec92094662b0b735e9c62c3938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ddc93cc8a1f4f1a8aedae30c5b11179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d7f5635f00a464d9271549eb28120cf",
              "IPY_MODEL_c17acdfe7ad44754ab05acaee0c5829e",
              "IPY_MODEL_ed7a5a37b14243d5a56610ebb6d9f951"
            ],
            "layout": "IPY_MODEL_40a8acc274c54598bc9bc31dfa205b93"
          }
        },
        "7d7f5635f00a464d9271549eb28120cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffce1b42634f44abb9f6df2827cd5c99",
            "placeholder": "​",
            "style": "IPY_MODEL_643a8775f35342edb985cfd29dc963ac",
            "value": "Map: 100%"
          }
        },
        "c17acdfe7ad44754ab05acaee0c5829e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cd9b780722045aa92713f1e0076d09c",
            "max": 480,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1036434cb0784c6cb6b2b7ffdfa09e4e",
            "value": 480
          }
        },
        "ed7a5a37b14243d5a56610ebb6d9f951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ee1670b508c4e319475bc8284842a51",
            "placeholder": "​",
            "style": "IPY_MODEL_94f238cd12a94a5e8681c24ae2af59bf",
            "value": " 480/480 [00:00&lt;00:00, 14315.13 examples/s]"
          }
        },
        "40a8acc274c54598bc9bc31dfa205b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffce1b42634f44abb9f6df2827cd5c99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "643a8775f35342edb985cfd29dc963ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cd9b780722045aa92713f1e0076d09c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1036434cb0784c6cb6b2b7ffdfa09e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ee1670b508c4e319475bc8284842a51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94f238cd12a94a5e8681c24ae2af59bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d25d3a7b410045bb9fce43509066c364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb3891be3ed74ddc87ce8a1ebc2973b6",
              "IPY_MODEL_75461fb629ad415eb3f0ebe12db22696",
              "IPY_MODEL_0d2b7fadf52a4994b6d5ddc1e4fd1a9f"
            ],
            "layout": "IPY_MODEL_a671fb491a6941b5a93bf6a573e694ae"
          }
        },
        "fb3891be3ed74ddc87ce8a1ebc2973b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aafc3aeb17c4ef19da98092ddb441f6",
            "placeholder": "​",
            "style": "IPY_MODEL_46b260beed2e46cea37938607f90b83e",
            "value": "Map: 100%"
          }
        },
        "75461fb629ad415eb3f0ebe12db22696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d74ac7da173430eae402359bd8d0f39",
            "max": 120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbdffc025b814b4298409d4a54530290",
            "value": 120
          }
        },
        "0d2b7fadf52a4994b6d5ddc1e4fd1a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b40e05732a848f6a3d7f296f94f2e59",
            "placeholder": "​",
            "style": "IPY_MODEL_2e15cf85703042af9ad22ad0b69e3d9a",
            "value": " 120/120 [00:00&lt;00:00, 5131.01 examples/s]"
          }
        },
        "a671fb491a6941b5a93bf6a573e694ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aafc3aeb17c4ef19da98092ddb441f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46b260beed2e46cea37938607f90b83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d74ac7da173430eae402359bd8d0f39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbdffc025b814b4298409d4a54530290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b40e05732a848f6a3d7f296f94f2e59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e15cf85703042af9ad22ad0b69e3d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9e0a37a1ba341c2b1448f7a5213e463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b898aad6e7004142b4fa13dc3ec5003c",
              "IPY_MODEL_7d2ee5b19dbc4147af200d47a87672b7",
              "IPY_MODEL_3920b321ba594c8292fc25610b776cdd"
            ],
            "layout": "IPY_MODEL_fdb0ef5e8ee841d2b7c1eab760d8c285"
          }
        },
        "b898aad6e7004142b4fa13dc3ec5003c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36ad1c4fe2c1467fa440e94ba553e306",
            "placeholder": "​",
            "style": "IPY_MODEL_0980f602e791476ebd37e9ed2d284543",
            "value": "config.json: 100%"
          }
        },
        "7d2ee5b19dbc4147af200d47a87672b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_292e081ea45e4a8fa28870b88badaabf",
            "max": 569,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb1d56cb9201467598a673492ec27e45",
            "value": 569
          }
        },
        "3920b321ba594c8292fc25610b776cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_007dc1327c7a4a04af370ebb8602a439",
            "placeholder": "​",
            "style": "IPY_MODEL_f955f4f8567a4eafa7e4615a8c7cff1d",
            "value": " 569/569 [00:00&lt;00:00, 46.2kB/s]"
          }
        },
        "fdb0ef5e8ee841d2b7c1eab760d8c285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36ad1c4fe2c1467fa440e94ba553e306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0980f602e791476ebd37e9ed2d284543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "292e081ea45e4a8fa28870b88badaabf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb1d56cb9201467598a673492ec27e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "007dc1327c7a4a04af370ebb8602a439": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f955f4f8567a4eafa7e4615a8c7cff1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af4fad602c3444078591c65aa90fd06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25a64611142247829fc1f692defb6a0b",
              "IPY_MODEL_270be6c8fe164910897a67de83f6fc43",
              "IPY_MODEL_187ffe00356e4c69a08d2478c3a24e7c"
            ],
            "layout": "IPY_MODEL_f02188f57f6e4b039a3cbe2f58b807da"
          }
        },
        "25a64611142247829fc1f692defb6a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44c01104c64d4b0d9a6e8b7de34b9ff5",
            "placeholder": "​",
            "style": "IPY_MODEL_baa2674453624873813daa3a2a65b833",
            "value": "model.safetensors: 100%"
          }
        },
        "270be6c8fe164910897a67de83f6fc43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58d0645431ff4988948500f03fa4ba6c",
            "max": 374998696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51cdb01e0e3f433c8874d063305556ad",
            "value": 374998696
          }
        },
        "187ffe00356e4c69a08d2478c3a24e7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bd0cd8260a941e38af15585939324b1",
            "placeholder": "​",
            "style": "IPY_MODEL_09307b7d15194ebfa8ec6dfda2325ced",
            "value": " 375M/375M [00:00&lt;00:00, 400MB/s]"
          }
        },
        "f02188f57f6e4b039a3cbe2f58b807da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44c01104c64d4b0d9a6e8b7de34b9ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baa2674453624873813daa3a2a65b833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58d0645431ff4988948500f03fa4ba6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51cdb01e0e3f433c8874d063305556ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bd0cd8260a941e38af15585939324b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09307b7d15194ebfa8ec6dfda2325ced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simplifine-llm/Simplifine/blob/main/examples/cloud_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Simplifine-tuning your LLMs! 💫\n",
        "\n",
        "This is a quick guide on getting started with Simplifine!\n",
        "\n",
        "Below is an example of sending a supervised fine-tuning job to Simplifine's hosted servers.\n",
        "\n",
        "First, we start by downloading Simplifine's latest version from github."
      ],
      "metadata": {
        "id": "wMs0O0fMLbkY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbF02GaxLSw8",
        "outputId": "f74ee822-ca88-42c5-f028-aea13c96f8ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.6/303.6 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for simplifine-alpha (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.5.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/simplifine-llm/Simplifine.git -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supervised fine tuning is a useful method to fine-tune a model for generating formatted answers, based on the provided input.\n",
        "\n",
        "An example would be to generate an answer based on provided context.\n",
        "\n",
        "An example would be:\n",
        "\n",
        "QUESTION: What is the capital France?\n",
        "\n",
        "CONTEXT: France has had its capital as Paris for some time now!\n",
        "\n",
        "ANSWER: Paris is the capital of France.\n",
        "\n",
        "In this example, you would want the model to fill in for the answer, having provided it with the question and context.\n",
        "\n",
        "In this example, an arbitrary dataset will be used. We will use the following prompt template:\n",
        "\n",
        "```\n",
        "'''### TITLE: {title}\\n ### ABSTRACT: {abstract}\\n ###EXPLANATION: {explanation}'''\n",
        "```\n",
        "\n",
        "Then as mentioned, we want the model to fill in the text for answer, so we asign this to a response template:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "response_template='\\n ###EXPLANATION:'\n",
        "```\n",
        "\n",
        "In the example below, we use our own dataset. This dataset should be a python dictionary, which should include the keys that are required to populate the template you provided. You can also use any dataset hosted on huggingface (some require authentication/tokens)"
      ],
      "metadata": {
        "id": "_hSHffSjLhSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from simplifine_alpha import train_engine\n",
        "import wandb\n",
        "import os\n",
        "\n",
        "# disabling WandB logging, change if you'd like to have one.\n",
        "# Note that you will need a wandb token.\n",
        "wandb.init(mode='disabled')\n",
        "\n",
        "# You can provided a HF dataset name.\n",
        "# be sure to change the keys, response template and tempalte accordingly.\n",
        "template = '''### TITLE: {title}\\n ### ABSTRACT: {abstract}\\n ###EXPLANATION: {explanation}'''\n",
        "response_template='\\n ###EXPLANATION:'\n",
        "keys = ['title', 'abstract', 'explanation']\n",
        "dataset_name=''\n",
        "\n",
        "# you can change the model. bigger models might throw OOM errors.\n",
        "model_name = 'EleutherAI/pythia-160m'\n",
        "\n",
        "from_hf = True\n",
        "if True:  # change this if you want to try this on a dataset on huggingface!\n",
        "  from_hf = False\n",
        "  data = {\n",
        "      'title':['title 1', 'title 2', 'title 3']*200,\n",
        "      'abstract':['abstract 1', 'abstract 2', 'abstract 3']*200,\n",
        "      'explanation':['explanation 1', 'explanation 2', 'explanation 3']*200\n",
        "  }\n",
        "\n",
        "train_engine.hf_sft(model_name, from_hf=from_hf, dataset_name=dataset_name,\n",
        "        keys = keys, data = data,\n",
        "        template = template,\n",
        "        response_template=response_template, zero=False, ddp=False, gradient_accumulation_steps=4, fp16=True, max_seq_length=2048)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623,
          "referenced_widgets": [
            "11192f5f2a0f419abc73a0b19b778bc8",
            "354f48b02ffe42189cde2221ad1410b4",
            "3075ac4886474981aa4ff5346031d59e",
            "6b35e9ce3e684dd3aefbc0b413a7f4b5",
            "4576c6f8758b4ce0a20e1becfe1f5d41",
            "b61bd3786bef452b938611ca8f8425ad",
            "f81226a58e544f7283f7d8e22e4dffe6",
            "60a4dc08f4134011910fe5d2740cf821",
            "b034da9e06be4f6f9f21a4f01f1c85d2",
            "3e740156fc704c8fa4046f1c42ba513e",
            "1add250a0ca34f2b83a4cf773d44f433",
            "58cd9e66a03e45f5bf5054a9905948b5",
            "bff58105f90145869fbf6c5a49399c31",
            "d741ff2bc9914811a2cf2016d61b5ab0",
            "12b642c93fd34118b6d57ae38b6290ec",
            "c50ed3d16c4a4d10a35be8eb80a2198d",
            "4837b95ac97d40c1a5bab60d72eb34d6",
            "8a9ce28a49d84d03b03c9c15e3a126dc",
            "15b34d19cb534e2da4bdb7ce63f26267",
            "4db10b1cd4094a78bf59abbbe862602c",
            "b340b7510add48ab8cf55f340afc2c15",
            "c6a85afeffd441a1812d685a132124a8",
            "70b470dd561c4589b056931f26e8a9bb",
            "3ae7713c09f24fe1a3f91cfdd22fbff9",
            "5dc27afea8344173a2130b6553eb5be8",
            "6fcfc1af885c41a987454c5ee34b945a",
            "7ca30f56c4c541ab97a17920facb482d",
            "af05a5aecb2a4046ac63d7c02b751ea0",
            "e46110a64b6345488b19560229db62ce",
            "3ce1b7d5a796496784c72c263e9f3181",
            "757d171f689b43a5afe610e65123904f",
            "57081f159ab44b4ebbc25d805cb3daa4",
            "45bd88ec92094662b0b735e9c62c3938",
            "4ddc93cc8a1f4f1a8aedae30c5b11179",
            "7d7f5635f00a464d9271549eb28120cf",
            "c17acdfe7ad44754ab05acaee0c5829e",
            "ed7a5a37b14243d5a56610ebb6d9f951",
            "40a8acc274c54598bc9bc31dfa205b93",
            "ffce1b42634f44abb9f6df2827cd5c99",
            "643a8775f35342edb985cfd29dc963ac",
            "4cd9b780722045aa92713f1e0076d09c",
            "1036434cb0784c6cb6b2b7ffdfa09e4e",
            "5ee1670b508c4e319475bc8284842a51",
            "94f238cd12a94a5e8681c24ae2af59bf",
            "d25d3a7b410045bb9fce43509066c364",
            "fb3891be3ed74ddc87ce8a1ebc2973b6",
            "75461fb629ad415eb3f0ebe12db22696",
            "0d2b7fadf52a4994b6d5ddc1e4fd1a9f",
            "a671fb491a6941b5a93bf6a573e694ae",
            "7aafc3aeb17c4ef19da98092ddb441f6",
            "46b260beed2e46cea37938607f90b83e",
            "7d74ac7da173430eae402359bd8d0f39",
            "bbdffc025b814b4298409d4a54530290",
            "6b40e05732a848f6a3d7f296f94f2e59",
            "2e15cf85703042af9ad22ad0b69e3d9a",
            "a9e0a37a1ba341c2b1448f7a5213e463",
            "b898aad6e7004142b4fa13dc3ec5003c",
            "7d2ee5b19dbc4147af200d47a87672b7",
            "3920b321ba594c8292fc25610b776cdd",
            "fdb0ef5e8ee841d2b7c1eab760d8c285",
            "36ad1c4fe2c1467fa440e94ba553e306",
            "0980f602e791476ebd37e9ed2d284543",
            "292e081ea45e4a8fa28870b88badaabf",
            "eb1d56cb9201467598a673492ec27e45",
            "007dc1327c7a4a04af370ebb8602a439",
            "f955f4f8567a4eafa7e4615a8c7cff1d",
            "af4fad602c3444078591c65aa90fd06f",
            "25a64611142247829fc1f692defb6a0b",
            "270be6c8fe164910897a67de83f6fc43",
            "187ffe00356e4c69a08d2478c3a24e7c",
            "f02188f57f6e4b039a3cbe2f58b807da",
            "44c01104c64d4b0d9a6e8b7de34b9ff5",
            "baa2674453624873813daa3a2a65b833",
            "58d0645431ff4988948500f03fa4ba6c",
            "51cdb01e0e3f433c8874d063305556ad",
            "6bd0cd8260a941e38af15585939324b1",
            "09307b7d15194ebfa8ec6dfda2325ced"
          ]
        },
        "id": "ctDa_6sMLiY9",
        "outputId": "517bdad1-540b-4ad3-e595-8efc3186a55b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-07-28 18:09:39,647] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11192f5f2a0f419abc73a0b19b778bc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58cd9e66a03e45f5bf5054a9905948b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70b470dd561c4589b056931f26e8a9bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ddc93cc8a1f4f1a8aedae30c5b11179"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/120 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d25d3a7b410045bb9fce43509066c364"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/569 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9e0a37a1ba341c2b1448f7a5213e463"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/375M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af4fad602c3444078591c65aa90fd06f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CUDA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:505: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [360/360 01:17, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the model's generation after training.\n",
        "The simplifine trainer saves the final model in a folder in output_dir called \"final_model\"."
      ],
      "metadata": {
        "id": "fWjphDgAMxuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# This the path that the model and other relevant files are saved to.\n",
        "# this is the default folder name in the trainer.\n",
        "# The final checkpoint is saved under final_model.\n",
        "path = '/content/sft_output/final_model'\n",
        "sf_model = AutoModelForCausalLM.from_pretrained(path)\n",
        "sf_tokenizer = AutoTokenizer.from_pretrained(path)\n",
        "\n",
        "# an example following the arbitrary training data\n",
        "input_example = '''### TITLE: title 1\\n ### ABSTRACT: abstract 1\\n ###EXPLANATION: '''\n",
        "\n",
        "input_example = sf_tokenizer(input_example, return_tensors='pt')\n",
        "\n",
        "output = sf_model.generate(input_example['input_ids'],\n",
        "                           attention_mask=input_example['attention_mask'],\n",
        "                           max_length=30,eos_token_id=sf_tokenizer.eos_token_id,\n",
        "                           early_stopping=True,\n",
        "                           pad_token_id=sf_tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "print(sf_tokenizer.decode(output[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYv_RPZWMzdD",
        "outputId": "7d6b8222-94de-4a61-9f48-dd69cc5d846f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### TITLE: title 1\n",
            " ### ABSTRACT: abstract 1\n",
            " ###EXPLANATION:  explanation 1 3 explanation 1 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Simplifine's GPU clusters\n",
        "\n",
        "In the example above, a small Pythia model (160m parameters) on a L4 GPU. Note that we do not use any adapters e.g. LoRA.\n",
        "In the next step, we show how simplifine allows to carry out the same thing, but on GPU clusters. This will use functions of train_utils.\n",
        "\n",
        "By using this command, you can manually pass the parallelization method.\n",
        "\n",
        "If you have a model that is small enough, try using DDP. In this method, each processor (fansy word for GPU!) has a replica of the model and attends to a different sample.\n",
        "\n",
        "You can also utilize ZeRO from DeepSpeed. With this, you can shard the model parameters, activation states and gradients across the GPUs. You also have the option to offload some to CPUs, at the expense of lower throughput.\n",
        "\n",
        "**NOTE**: we currently support L4 and A100 gpus. When initilising the client, you can define which GPU you would like to run your job on. each server goes up to 8 gpus. The default is L4 GPUs."
      ],
      "metadata": {
        "id": "J0OQyt44M6Ei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using DDP to train\n",
        "The example below uses DDP to distribute the training process.\n",
        "\n",
        "\n",
        "you would need a simplifine API key. contact us for one for free! :)\n",
        "\n",
        "see contact details at our github repo at https://github.com/simplifine-llm/Simplifine/tree/main"
      ],
      "metadata": {
        "id": "csLAwuVmM8Va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from simplifine_alpha.train_utils import Client\n",
        "\n",
        "# setting up the client with\n",
        "# enter your simplifine api key below\n",
        "api_key = ''\n",
        "gpu_type = 'a100'  # l4 or a100\n",
        "client = Client(api_key=api_key, gpu_type=gpu_type)\n",
        "\n",
        "# simply pass all the arguements you used above, and change ddp ot zero if you want parallelization.\n",
        "client.sft_train_cloud(model_name = model_name, from_hf=from_hf, dataset_name=dataset_name,\n",
        "        keys = keys, data = data,\n",
        "        template = template, job_name='ddp_job',\n",
        "        response_template=response_template, use_zero=False, use_ddp=True)"
      ],
      "metadata": {
        "id": "ynn-NEDEM5qU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After sending the query, you can check the status of your jobs. Note that the status is one of the three options:\n",
        "```text\n",
        "status = complete|in progress|pending\n",
        "```"
      ],
      "metadata": {
        "id": "I0cXnfYQPogc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "status = client.get_all_jobs()\n",
        "for num,i in enumerate(status[-5:]):\n",
        "  print(f'Job {num}: {i}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AulHnk5-Pqh8",
        "outputId": "375a3336-2ecf-46d1-97e2-f4df5b003686"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job 0: {'job_id': '544bb4f0-206f-43b7-850e-5e1e9f7b4d23', 'job_name': 'job-4', 'status': 'completed'}\n",
            "Job 1: {'job_id': 'bde91132-9776-41ae-89f9-855dfb116a91', 'job_name': 'ddp_job', 'status': 'completed'}\n",
            "Job 2: {'job_id': 'a1ff54dd-5ee2-4e35-9e78-6868f63dad37', 'job_name': 'zero_example_cloud', 'status': 'completed'}\n",
            "Job 3: {'job_id': '543d3bc3-3ce4-4af6-9f9a-6c0823dcc9b0', 'job_name': 'ddp_job', 'status': 'in progress'}\n",
            "Job 4: {'job_id': '5d55d46a-7793-4c06-9cef-279f03a0f953', 'job_name': 'job_1', 'status': 'pending'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also stop an ongoing job, by calling the function below"
      ],
      "metadata": {
        "id": "nPgJBtDbXola"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_running_job = False\n",
        "if stop_running_job:\n",
        "  job_id = status[-1]['job_id']\n",
        "  client.stop_job(job_id)"
      ],
      "metadata": {
        "id": "AG5HVYBAXr0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the job_id of the last job\n",
        "job_id = status[-1]['job_id']\n",
        "\n",
        "logs = client.get_train_logs(job_id)\n",
        "print(logs['response'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziFDfaygbzOl",
        "outputId": "2e2ca538-f85d-4a87-e50b-442a226fb25b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W0728 18:13:03.377000 134787342856320 torch/distributed/run.py:779] \n",
            "W0728 18:13:03.377000 134787342856320 torch/distributed/run.py:779] *****************************************\n",
            "W0728 18:13:03.377000 134787342856320 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
            "W0728 18:13:03.377000 134787342856320 torch/distributed/run.py:779] *****************************************\n",
            "[2024-07-28 18:13:08,712] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "[2024-07-28 18:13:08,803] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_fwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_bwd\n",
            "[2024-07-28 18:13:08,963] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "[2024-07-28 18:13:09,002] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_fwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_bwd\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "[2024-07-28 18:13:09,067] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-07-28 18:13:09,073] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-07-28 18:13:09,075] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "[2024-07-28 18:13:09,083] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_fwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_bwd\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_fwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_bwd\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_fwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_bwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_fwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_bwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_fwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_bwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_fwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_bwd\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "\n",
            "Map:   0%|          | 0/480 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 480/480 [00:00<00:00, 27874.92 examples/s]\n",
            "\n",
            "Map:   0%|          | 0/120 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 120/120 [00:00<00:00, 15003.32 examples/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "\n",
            "Map:   0%|          | 0/480 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 480/480 [00:00<00:00, 27687.08 examples/s]\n",
            "\n",
            "Map:   0%|          | 0/120 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 120/120 [00:00<00:00, 13977.91 examples/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "\n",
            "Map:   0%|          | 0/480 [00:00<?, ? examples/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "\n",
            "Map: 100%|██████████| 480/480 [00:00<00:00, 25838.26 examples/s]\n",
            "\n",
            "Map:   0%|          | 0/120 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 120/120 [00:00<00:00, 13956.59 examples/s]\n",
            "\n",
            "Map:   0%|          | 0/480 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 480/480 [00:00<00:00, 27829.07 examples/s]\n",
            "\n",
            "Map:   0%|          | 0/120 [00:00<?, ? examples/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "\n",
            "Map: 100%|██████████| 120/120 [00:00<00:00, 14669.67 examples/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "\n",
            "Map:   0%|          | 0/480 [00:00<?, ? examples/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "\n",
            "Map:   0%|          | 0/480 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 480/480 [00:00<00:00, 26593.92 examples/s]\n",
            "\n",
            "Map: 100%|██████████| 480/480 [00:00<00:00, 26710.35 examples/s]\n",
            "\n",
            "Map:   0%|          | 0/480 [00:00<?, ? examples/s]\n",
            "Map:   0%|          | 0/120 [00:00<?, ? examples/s]\n",
            "Map:   0%|          | 0/480 [00:00<?, ? examples/s]\n",
            "Map:   0%|          | 0/120 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 120/120 [00:00<00:00, 9773.33 examples/s]\n",
            "\n",
            "Map: 100%|██████████| 480/480 [00:00<00:00, 19004.19 examples/s]\n",
            "\n",
            "Map: 100%|██████████| 120/120 [00:00<00:00, 13260.87 examples/s]\n",
            "\n",
            "Map: 100%|██████████| 480/480 [00:00<00:00, 24817.45 examples/s]\n",
            "\n",
            "Map:   0%|          | 0/120 [00:00<?, ? examples/s]\n",
            "Map:   0%|          | 0/120 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 120/120 [00:00<00:00, 13024.10 examples/s]\n",
            "\n",
            "Map: 100%|██████████| 120/120 [00:00<00:00, 13083.01 examples/s]\n",
            "Using CUDA\n",
            "Initializing process group for DDP\n",
            "Using CUDA\n",
            "Initializing process group for DDP\n",
            "Using CUDA\n",
            "Initializing process group for DDP\n",
            "Using CUDA\n",
            "Initializing process group for DDP\n",
            "Using CUDA\n",
            "Initializing process group for DDP\n",
            "Using CUDA\n",
            "Initializing process group for DDP\n",
            "Using CUDA\n",
            "Initializing process group for DDP\n",
            "Using CUDA\n",
            "Initializing process group for DDP\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:494: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:494: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:494: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:494: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:494: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:494: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:494: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:494: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
            "  warnings.warn(\n",
            "\n",
            "  0%|          | 0/60 [00:00<?, ?it/s]\n",
            "  2%|▏         | 1/60 [00:00<00:51,  1.14it/s]\n",
            "  7%|▋         | 4/60 [00:01<00:11,  4.87it/s]\n",
            " 12%|█▏        | 7/60 [00:01<00:06,  8.22it/s]\n",
            " 17%|█▋        | 10/60 [00:01<00:04, 11.04it/s]\n",
            " 22%|██▏       | 13/60 [00:01<00:03, 13.51it/s]\n",
            " 27%|██▋       | 16/60 [00:01<00:02, 15.44it/s]\n",
            " 32%|███▏      | 19/60 [00:01<00:02, 16.91it/s]\n",
            " 37%|███▋      | 22/60 [00:01<00:02, 17.96it/s]\n",
            " 42%|████▏     | 25/60 [00:02<00:01, 18.82it/s]\n",
            " 47%|████▋     | 28/60 [00:02<00:01, 19.44it/s]\n",
            " 52%|█████▏    | 31/60 [00:02<00:01, 19.90it/s]\n",
            " 57%|█████▋    | 34/60 [00:02<00:01, 20.22it/s]\n",
            " 62%|██████▏   | 37/60 [00:02<00:01, 20.47it/s]\n",
            " 67%|██████▋   | 40/60 [00:02<00:00, 20.65it/s]\n",
            " 72%|███████▏  | 43/60 [00:02<00:00, 20.75it/s]\n",
            " 77%|███████▋  | 46/60 [00:03<00:00, 20.79it/s]\n",
            " 82%|████████▏ | 49/60 [00:03<00:00, 20.83it/s]\n",
            " 87%|████████▋ | 52/60 [00:03<00:00, 20.90it/s]\n",
            " 92%|█████████▏| 55/60 [00:03<00:00, 20.94it/s]\n",
            " 97%|█████████▋| 58/60 [00:03<00:00, 20.98it/s]\n",
            "                                               \n",
            "{'train_runtime': 6.5488, 'train_samples_per_second': 73.295, 'train_steps_per_second': 9.162, 'train_loss': 0.1135852018992106, 'epoch': 1.0}\n",
            "\n",
            "100%|██████████| 60/60 [00:06<00:00, 20.98it/s]\n",
            "100%|██████████| 60/60 [00:06<00:00,  9.16it/s]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading\n",
        "The trained model can be downloaded using the \"download_model\" function. it will be a zip file."
      ],
      "metadata": {
        "id": "6kqPRkPNgK07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# creating a folder to store the model\n",
        "os.mkdir('sf_trained_model')\n",
        "\n",
        "# download and save the model to it.\n",
        "# This might take some time, have a sip of that coffee! :)\n",
        "client.download_model(job_id=job_id, extract_to='/content/sf_trained_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivuJ8634gMVr",
        "outputId": "8cc93aef-5a38-4389-d956-ec24451af393"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: 100%|██████████| 540M/540M [00:36<00:00, 14.9MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Directory downloaded successfully and saved to /content/sf_trained_model/5d55d46a-7793-4c06-9cef-279f03a0f953.zip\n",
            "Model unzipped successfully to /content/sf_trained_model\n",
            "Deleted the zip file at /content/sf_trained_model/5d55d46a-7793-4c06-9cef-279f03a0f953.zip\n",
            "Model downloaded, unzipped, and zip file deleted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we test loading the model!"
      ],
      "metadata": {
        "id": "67SHOrw0gUhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "path = '/content/sf_trained_model'\n",
        "sf_model = AutoModelForCausalLM.from_pretrained(path)\n",
        "sf_tokenizer = AutoTokenizer.from_pretrained(path)\n",
        "\n",
        "input_example = '''### TITLE: title 1\\n ### ABSTRACT: abstract 1\\n ###EXPLANATION: '''\n",
        "\n",
        "input_example = sf_tokenizer(input_example, return_tensors='pt')\n",
        "\n",
        "output = sf_model.generate(input_example['input_ids'],\n",
        "                           attention_mask=input_example['attention_mask'],\n",
        "                           max_length=30,eos_token_id=sf_tokenizer.eos_token_id,\n",
        "                           early_stopping=True,\n",
        "                           pad_token_id=sf_tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "print(sf_tokenizer.decode(output[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsUWweRdgVgZ",
        "outputId": "ac088e5b-a57d-4640-d8ab-74bdbe631dbc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/sf_trained_model were not used when initializing GPTNeoXForCausalLM: ['module.embed_out.weight', 'module.gpt_neox.embed_in.weight', 'module.gpt_neox.final_layer_norm.bias', 'module.gpt_neox.final_layer_norm.weight', 'module.gpt_neox.layers.0.attention.dense.bias', 'module.gpt_neox.layers.0.attention.dense.weight', 'module.gpt_neox.layers.0.attention.query_key_value.bias', 'module.gpt_neox.layers.0.attention.query_key_value.weight', 'module.gpt_neox.layers.0.input_layernorm.bias', 'module.gpt_neox.layers.0.input_layernorm.weight', 'module.gpt_neox.layers.0.mlp.dense_4h_to_h.bias', 'module.gpt_neox.layers.0.mlp.dense_4h_to_h.weight', 'module.gpt_neox.layers.0.mlp.dense_h_to_4h.bias', 'module.gpt_neox.layers.0.mlp.dense_h_to_4h.weight', 'module.gpt_neox.layers.0.post_attention_layernorm.bias', 'module.gpt_neox.layers.0.post_attention_layernorm.weight', 'module.gpt_neox.layers.1.attention.dense.bias', 'module.gpt_neox.layers.1.attention.dense.weight', 'module.gpt_neox.layers.1.attention.query_key_value.bias', 'module.gpt_neox.layers.1.attention.query_key_value.weight', 'module.gpt_neox.layers.1.input_layernorm.bias', 'module.gpt_neox.layers.1.input_layernorm.weight', 'module.gpt_neox.layers.1.mlp.dense_4h_to_h.bias', 'module.gpt_neox.layers.1.mlp.dense_4h_to_h.weight', 'module.gpt_neox.layers.1.mlp.dense_h_to_4h.bias', 'module.gpt_neox.layers.1.mlp.dense_h_to_4h.weight', 'module.gpt_neox.layers.1.post_attention_layernorm.bias', 'module.gpt_neox.layers.1.post_attention_layernorm.weight', 'module.gpt_neox.layers.10.attention.dense.bias', 'module.gpt_neox.layers.10.attention.dense.weight', 'module.gpt_neox.layers.10.attention.query_key_value.bias', 'module.gpt_neox.layers.10.attention.query_key_value.weight', 'module.gpt_neox.layers.10.input_layernorm.bias', 'module.gpt_neox.layers.10.input_layernorm.weight', 'module.gpt_neox.layers.10.mlp.dense_4h_to_h.bias', 'module.gpt_neox.layers.10.mlp.dense_4h_to_h.weight', 'module.gpt_neox.layers.10.mlp.dense_h_to_4h.bias', 'module.gpt_neox.layers.10.mlp.dense_h_to_4h.weight', 'module.gpt_neox.layers.10.post_attention_layernorm.bias', 'module.gpt_neox.layers.10.post_attention_layernorm.weight', 'module.gpt_neox.layers.11.attention.dense.bias', 'module.gpt_neox.layers.11.attention.dense.weight', 'module.gpt_neox.layers.11.attention.query_key_value.bias', 'module.gpt_neox.layers.11.attention.query_key_value.weight', 'module.gpt_neox.layers.11.input_layernorm.bias', 'module.gpt_neox.layers.11.input_layernorm.weight', 'module.gpt_neox.layers.11.mlp.dense_4h_to_h.bias', 'module.gpt_neox.layers.11.mlp.dense_4h_to_h.weight', 'module.gpt_neox.layers.11.mlp.dense_h_to_4h.bias', 'module.gpt_neox.layers.11.mlp.dense_h_to_4h.weight', 'module.gpt_neox.layers.11.post_attention_layernorm.bias', 'module.gpt_neox.layers.11.post_attention_layernorm.weight', 'module.gpt_neox.layers.2.attention.dense.bias', 'module.gpt_neox.layers.2.attention.dense.weight', 'module.gpt_neox.layers.2.attention.query_key_value.bias', 'module.gpt_neox.layers.2.attention.query_key_value.weight', 'module.gpt_neox.layers.2.input_layernorm.bias', 'module.gpt_neox.layers.2.input_layernorm.weight', 'module.gpt_neox.layers.2.mlp.dense_4h_to_h.bias', 'module.gpt_neox.layers.2.mlp.dense_4h_to_h.weight', 'module.gpt_neox.layers.2.mlp.dense_h_to_4h.bias', 'module.gpt_neox.layers.2.mlp.dense_h_to_4h.weight', 'module.gpt_neox.layers.2.post_attention_layernorm.bias', 'module.gpt_neox.layers.2.post_attention_layernorm.weight', 'module.gpt_neox.layers.3.attention.dense.bias', 'module.gpt_neox.layers.3.attention.dense.weight', 'module.gpt_neox.layers.3.attention.query_key_value.bias', 'module.gpt_neox.layers.3.attention.query_key_value.weight', 'module.gpt_neox.layers.3.input_layernorm.bias', 'module.gpt_neox.layers.3.input_layernorm.weight', 'module.gpt_neox.layers.3.mlp.dense_4h_to_h.bias', 'module.gpt_neox.layers.3.mlp.dense_4h_to_h.weight', 'module.gpt_neox.layers.3.mlp.dense_h_to_4h.bias', 'module.gpt_neox.layers.3.mlp.dense_h_to_4h.weight', 'module.gpt_neox.layers.3.post_attention_layernorm.bias', 'module.gpt_neox.layers.3.post_attention_layernorm.weight', 'module.gpt_neox.layers.4.attention.dense.bias', 'module.gpt_neox.layers.4.attention.dense.weight', 'module.gpt_neox.layers.4.attention.query_key_value.bias', 'module.gpt_neox.layers.4.attention.query_key_value.weight', 'module.gpt_neox.layers.4.input_layernorm.bias', 'module.gpt_neox.layers.4.input_layernorm.weight', 'module.gpt_neox.layers.4.mlp.dense_4h_to_h.bias', 'module.gpt_neox.layers.4.mlp.dense_4h_to_h.weight', 'module.gpt_neox.layers.4.mlp.dense_h_to_4h.bias', 'module.gpt_neox.layers.4.mlp.dense_h_to_4h.weight', 'module.gpt_neox.layers.4.post_attention_layernorm.bias', 'module.gpt_neox.layers.4.post_attention_layernorm.weight', 'module.gpt_neox.layers.5.attention.dense.bias', 'module.gpt_neox.layers.5.attention.dense.weight', 'module.gpt_neox.layers.5.attention.query_key_value.bias', 'module.gpt_neox.layers.5.attention.query_key_value.weight', 'module.gpt_neox.layers.5.input_layernorm.bias', 'module.gpt_neox.layers.5.input_layernorm.weight', 'module.gpt_neox.layers.5.mlp.dense_4h_to_h.bias', 'module.gpt_neox.layers.5.mlp.dense_4h_to_h.weight', 'module.gpt_neox.layers.5.mlp.dense_h_to_4h.bias', 'module.gpt_neox.layers.5.mlp.dense_h_to_4h.weight', 'module.gpt_neox.layers.5.post_attention_layernorm.bias', 'module.gpt_neox.layers.5.post_attention_layernorm.weight', 'module.gpt_neox.layers.6.attention.dense.bias', 'module.gpt_neox.layers.6.attention.dense.weight', 'module.gpt_neox.layers.6.attention.query_key_value.bias', 'module.gpt_neox.layers.6.attention.query_key_value.weight', 'module.gpt_neox.layers.6.input_layernorm.bias', 'module.gpt_neox.layers.6.input_layernorm.weight', 'module.gpt_neox.layers.6.mlp.dense_4h_to_h.bias', 'module.gpt_neox.layers.6.mlp.dense_4h_to_h.weight', 'module.gpt_neox.layers.6.mlp.dense_h_to_4h.bias', 'module.gpt_neox.layers.6.mlp.dense_h_to_4h.weight', 'module.gpt_neox.layers.6.post_attention_layernorm.bias', 'module.gpt_neox.layers.6.post_attention_layernorm.weight', 'module.gpt_neox.layers.7.attention.dense.bias', 'module.gpt_neox.layers.7.attention.dense.weight', 'module.gpt_neox.layers.7.attention.query_key_value.bias', 'module.gpt_neox.layers.7.attention.query_key_value.weight', 'module.gpt_neox.layers.7.input_layernorm.bias', 'module.gpt_neox.layers.7.input_layernorm.weight', 'module.gpt_neox.layers.7.mlp.dense_4h_to_h.bias', 'module.gpt_neox.layers.7.mlp.dense_4h_to_h.weight', 'module.gpt_neox.layers.7.mlp.dense_h_to_4h.bias', 'module.gpt_neox.layers.7.mlp.dense_h_to_4h.weight', 'module.gpt_neox.layers.7.post_attention_layernorm.bias', 'module.gpt_neox.layers.7.post_attention_layernorm.weight', 'module.gpt_neox.layers.8.attention.dense.bias', 'module.gpt_neox.layers.8.attention.dense.weight', 'module.gpt_neox.layers.8.attention.query_key_value.bias', 'module.gpt_neox.layers.8.attention.query_key_value.weight', 'module.gpt_neox.layers.8.input_layernorm.bias', 'module.gpt_neox.layers.8.input_layernorm.weight', 'module.gpt_neox.layers.8.mlp.dense_4h_to_h.bias', 'module.gpt_neox.layers.8.mlp.dense_4h_to_h.weight', 'module.gpt_neox.layers.8.mlp.dense_h_to_4h.bias', 'module.gpt_neox.layers.8.mlp.dense_h_to_4h.weight', 'module.gpt_neox.layers.8.post_attention_layernorm.bias', 'module.gpt_neox.layers.8.post_attention_layernorm.weight', 'module.gpt_neox.layers.9.attention.dense.bias', 'module.gpt_neox.layers.9.attention.dense.weight', 'module.gpt_neox.layers.9.attention.query_key_value.bias', 'module.gpt_neox.layers.9.attention.query_key_value.weight', 'module.gpt_neox.layers.9.input_layernorm.bias', 'module.gpt_neox.layers.9.input_layernorm.weight', 'module.gpt_neox.layers.9.mlp.dense_4h_to_h.bias', 'module.gpt_neox.layers.9.mlp.dense_4h_to_h.weight', 'module.gpt_neox.layers.9.mlp.dense_h_to_4h.bias', 'module.gpt_neox.layers.9.mlp.dense_h_to_4h.weight', 'module.gpt_neox.layers.9.post_attention_layernorm.bias', 'module.gpt_neox.layers.9.post_attention_layernorm.weight']\n",
            "- This IS expected if you are initializing GPTNeoXForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPTNeoXForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of GPTNeoXForCausalLM were not initialized from the model checkpoint at /content/sf_trained_model and are newly initialized: ['embed_in.weight', 'embed_out.weight', 'final_layer_norm.bias', 'final_layer_norm.weight', 'layers.0.attention.dense.bias', 'layers.0.attention.dense.weight', 'layers.0.attention.query_key_value.bias', 'layers.0.attention.query_key_value.weight', 'layers.0.input_layernorm.bias', 'layers.0.input_layernorm.weight', 'layers.0.mlp.dense_4h_to_h.bias', 'layers.0.mlp.dense_4h_to_h.weight', 'layers.0.mlp.dense_h_to_4h.bias', 'layers.0.mlp.dense_h_to_4h.weight', 'layers.0.post_attention_layernorm.bias', 'layers.0.post_attention_layernorm.weight', 'layers.1.attention.dense.bias', 'layers.1.attention.dense.weight', 'layers.1.attention.query_key_value.bias', 'layers.1.attention.query_key_value.weight', 'layers.1.input_layernorm.bias', 'layers.1.input_layernorm.weight', 'layers.1.mlp.dense_4h_to_h.bias', 'layers.1.mlp.dense_4h_to_h.weight', 'layers.1.mlp.dense_h_to_4h.bias', 'layers.1.mlp.dense_h_to_4h.weight', 'layers.1.post_attention_layernorm.bias', 'layers.1.post_attention_layernorm.weight', 'layers.10.attention.dense.bias', 'layers.10.attention.dense.weight', 'layers.10.attention.query_key_value.bias', 'layers.10.attention.query_key_value.weight', 'layers.10.input_layernorm.bias', 'layers.10.input_layernorm.weight', 'layers.10.mlp.dense_4h_to_h.bias', 'layers.10.mlp.dense_4h_to_h.weight', 'layers.10.mlp.dense_h_to_4h.bias', 'layers.10.mlp.dense_h_to_4h.weight', 'layers.10.post_attention_layernorm.bias', 'layers.10.post_attention_layernorm.weight', 'layers.11.attention.dense.bias', 'layers.11.attention.dense.weight', 'layers.11.attention.query_key_value.bias', 'layers.11.attention.query_key_value.weight', 'layers.11.input_layernorm.bias', 'layers.11.input_layernorm.weight', 'layers.11.mlp.dense_4h_to_h.bias', 'layers.11.mlp.dense_4h_to_h.weight', 'layers.11.mlp.dense_h_to_4h.bias', 'layers.11.mlp.dense_h_to_4h.weight', 'layers.11.post_attention_layernorm.bias', 'layers.11.post_attention_layernorm.weight', 'layers.2.attention.dense.bias', 'layers.2.attention.dense.weight', 'layers.2.attention.query_key_value.bias', 'layers.2.attention.query_key_value.weight', 'layers.2.input_layernorm.bias', 'layers.2.input_layernorm.weight', 'layers.2.mlp.dense_4h_to_h.bias', 'layers.2.mlp.dense_4h_to_h.weight', 'layers.2.mlp.dense_h_to_4h.bias', 'layers.2.mlp.dense_h_to_4h.weight', 'layers.2.post_attention_layernorm.bias', 'layers.2.post_attention_layernorm.weight', 'layers.3.attention.dense.bias', 'layers.3.attention.dense.weight', 'layers.3.attention.query_key_value.bias', 'layers.3.attention.query_key_value.weight', 'layers.3.input_layernorm.bias', 'layers.3.input_layernorm.weight', 'layers.3.mlp.dense_4h_to_h.bias', 'layers.3.mlp.dense_4h_to_h.weight', 'layers.3.mlp.dense_h_to_4h.bias', 'layers.3.mlp.dense_h_to_4h.weight', 'layers.3.post_attention_layernorm.bias', 'layers.3.post_attention_layernorm.weight', 'layers.4.attention.dense.bias', 'layers.4.attention.dense.weight', 'layers.4.attention.query_key_value.bias', 'layers.4.attention.query_key_value.weight', 'layers.4.input_layernorm.bias', 'layers.4.input_layernorm.weight', 'layers.4.mlp.dense_4h_to_h.bias', 'layers.4.mlp.dense_4h_to_h.weight', 'layers.4.mlp.dense_h_to_4h.bias', 'layers.4.mlp.dense_h_to_4h.weight', 'layers.4.post_attention_layernorm.bias', 'layers.4.post_attention_layernorm.weight', 'layers.5.attention.dense.bias', 'layers.5.attention.dense.weight', 'layers.5.attention.query_key_value.bias', 'layers.5.attention.query_key_value.weight', 'layers.5.input_layernorm.bias', 'layers.5.input_layernorm.weight', 'layers.5.mlp.dense_4h_to_h.bias', 'layers.5.mlp.dense_4h_to_h.weight', 'layers.5.mlp.dense_h_to_4h.bias', 'layers.5.mlp.dense_h_to_4h.weight', 'layers.5.post_attention_layernorm.bias', 'layers.5.post_attention_layernorm.weight', 'layers.6.attention.dense.bias', 'layers.6.attention.dense.weight', 'layers.6.attention.query_key_value.bias', 'layers.6.attention.query_key_value.weight', 'layers.6.input_layernorm.bias', 'layers.6.input_layernorm.weight', 'layers.6.mlp.dense_4h_to_h.bias', 'layers.6.mlp.dense_4h_to_h.weight', 'layers.6.mlp.dense_h_to_4h.bias', 'layers.6.mlp.dense_h_to_4h.weight', 'layers.6.post_attention_layernorm.bias', 'layers.6.post_attention_layernorm.weight', 'layers.7.attention.dense.bias', 'layers.7.attention.dense.weight', 'layers.7.attention.query_key_value.bias', 'layers.7.attention.query_key_value.weight', 'layers.7.input_layernorm.bias', 'layers.7.input_layernorm.weight', 'layers.7.mlp.dense_4h_to_h.bias', 'layers.7.mlp.dense_4h_to_h.weight', 'layers.7.mlp.dense_h_to_4h.bias', 'layers.7.mlp.dense_h_to_4h.weight', 'layers.7.post_attention_layernorm.bias', 'layers.7.post_attention_layernorm.weight', 'layers.8.attention.dense.bias', 'layers.8.attention.dense.weight', 'layers.8.attention.query_key_value.bias', 'layers.8.attention.query_key_value.weight', 'layers.8.input_layernorm.bias', 'layers.8.input_layernorm.weight', 'layers.8.mlp.dense_4h_to_h.bias', 'layers.8.mlp.dense_4h_to_h.weight', 'layers.8.mlp.dense_h_to_4h.bias', 'layers.8.mlp.dense_h_to_4h.weight', 'layers.8.post_attention_layernorm.bias', 'layers.8.post_attention_layernorm.weight', 'layers.9.attention.dense.bias', 'layers.9.attention.dense.weight', 'layers.9.attention.query_key_value.bias', 'layers.9.attention.query_key_value.weight', 'layers.9.input_layernorm.bias', 'layers.9.input_layernorm.weight', 'layers.9.mlp.dense_4h_to_h.bias', 'layers.9.mlp.dense_4h_to_h.weight', 'layers.9.mlp.dense_h_to_4h.bias', 'layers.9.mlp.dense_h_to_4h.weight', 'layers.9.post_attention_layernorm.bias', 'layers.9.post_attention_layernorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### TITLE: title 1\n",
            " ### ABSTRACT: abstract 1\n",
            " ###EXPLANATION: rugu stretmediate complains GermanServ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using ZeRO\n",
        "ZeRO is a strong tool when a model cannot fit on GPU memory, so it is sharded across them (parameters, gradients and activations). Further memory reduction could be by enabling fp16/bf16, and gradient_checkpointing."
      ],
      "metadata": {
        "id": "os5pt22OgZc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This time, we just change the use_zero arg to True, and opposite to use_ddp.\n",
        "client.sft_train_cloud(model_name = model_name, from_hf=from_hf, dataset_name=dataset_name,\n",
        "        keys = keys, data = data,\n",
        "        template = template, job_name='zero_example_cloud',\n",
        "        response_template=response_template, use_zero=True, use_ddp=False)"
      ],
      "metadata": {
        "id": "m3LGu5ZYga2y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# repeat the same step of extracting jobs and ids\n",
        "status = client.get_all_jobs()\n",
        "\n",
        "for num,i in enumerate(status[-5:]):\n",
        "  print(f'Number {num} status: {i}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poAxZn-bgcnC",
        "outputId": "a78dede0-ddbd-4d1a-f80d-4f9b06b16a90"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number 0 status: {'job_id': 'bde91132-9776-41ae-89f9-855dfb116a91', 'job_name': 'ddp_job', 'status': 'completed'}\n",
            "\n",
            "Number 1 status: {'job_id': 'a1ff54dd-5ee2-4e35-9e78-6868f63dad37', 'job_name': 'zero_example_cloud', 'status': 'completed'}\n",
            "\n",
            "Number 2 status: {'job_id': '543d3bc3-3ce4-4af6-9f9a-6c0823dcc9b0', 'job_name': 'ddp_job', 'status': 'completed'}\n",
            "\n",
            "Number 3 status: {'job_id': '5d55d46a-7793-4c06-9cef-279f03a0f953', 'job_name': 'job_1', 'status': 'completed'}\n",
            "\n",
            "Number 4 status: {'job_id': '42d965c0-773f-4b45-8dfb-a4f310e6606e', 'job_name': 'zero_example_cloud', 'status': 'in progress'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting logs again\n",
        "job_id = status[-1]['job_id']\n",
        "\n",
        "logs = client.get_train_logs(job_id)\n",
        "print(logs['response'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zHTeTBmgzm7",
        "outputId": "d5ada91a-76c1-48ac-df4b-ed35bf38661d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W0728 18:16:44.514000 133239404900480 torch/distributed/run.py:779] \n",
            "W0728 18:16:44.514000 133239404900480 torch/distributed/run.py:779] *****************************************\n",
            "W0728 18:16:44.514000 133239404900480 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
            "W0728 18:16:44.514000 133239404900480 torch/distributed/run.py:779] *****************************************\n",
            "[2024-07-28 18:16:49,912] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-07-28 18:16:49,967] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "[2024-07-28 18:16:50,049] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "[2024-07-28 18:16:50,075] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-07-28 18:16:50,082] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "[2024-07-28 18:16:50,149] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "[2024-07-28 18:16:50,153] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "[2024-07-28 18:16:50,168] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_fwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_bwd\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_fwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_bwd\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_fwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_bwd\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_fwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_bwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_fwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_bwd\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_fwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_bwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_fwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_bwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_fwd\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @autocast_custom_bwd\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "\n",
            "Map:   0%|          | 0/480 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 480/480 [00:00<00:00, 28000.14 examples/s]\n",
            "\n",
            "Map:   0%|          | 0/120 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 120/120 [00:00<00:00, 15290.94 examples/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "\n",
            "Map:   0%|          | 0/480 [00:00<?, ? examples/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "\n",
            "Map: 100%|██████████| 480/480 [00:00<00:00, 27097.90 examples/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "\n",
            "Map:   0%|          | 0/120 [00:00<?, ? examples/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "\n",
            "Map: 100%|██████████| 120/120 [00:00<00:00, 14466.03 examples/s]\n",
            "\n",
            "Map:   0%|          | 0/480 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 480/480 [00:00<00:00, 24955.57 examples/s]\n",
            "\n",
            "Map:   0%|          | 0/480 [00:00<?, ? examples/s]\n",
            "Map:   0%|          | 0/480 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 480/480 [00:00<00:00, 26237.63 examples/s]\n",
            "\n",
            "Map:   0%|          | 0/120 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 480/480 [00:00<00:00, 23259.42 examples/s]\n",
            "\n",
            "Map: 100%|██████████| 120/120 [00:00<00:00, 13279.77 examples/s]\n",
            "\n",
            "Map:   0%|          | 0/120 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 120/120 [00:00<00:00, 13359.07 examples/s]\n",
            "\n",
            "Map:   0%|          | 0/120 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 120/120 [00:00<00:00, 14175.93 examples/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "\n",
            "Map:   0%|          | 0/480 [00:00<?, ? examples/s]\n",
            "Map:   0%|          | 0/480 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 480/480 [00:00<00:00, 27207.77 examples/s]\n",
            "\n",
            "Map:   0%|          | 0/480 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 480/480 [00:00<00:00, 23907.40 examples/s]\n",
            "\n",
            "Map: 100%|██████████| 480/480 [00:00<00:00, 26135.45 examples/s]\n",
            "\n",
            "Map:   0%|          | 0/120 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 120/120 [00:00<00:00, 14730.64 examples/s]\n",
            "\n",
            "Map:   0%|          | 0/120 [00:00<?, ? examples/s]\n",
            "Map:   0%|          | 0/120 [00:00<?, ? examples/s]\n",
            "Map: 100%|██████████| 120/120 [00:00<00:00, 14727.62 examples/s]\n",
            "\n",
            "Map: 100%|██████████| 120/120 [00:00<00:00, 14245.34 examples/s]\n",
            "Using CUDA\n",
            "[2024-07-28 18:16:52,649] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2024-07-28 18:16:52,649] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "Using CUDA\n",
            "[2024-07-28 18:16:52,752] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:494: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
            "  warnings.warn(\n",
            "Using CUDA\n",
            "[2024-07-28 18:16:52,836] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "Using CUDA\n",
            "Using CUDA\n",
            "[2024-07-28 18:16:52,861] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2024-07-28 18:16:52,863] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "Using CUDA\n",
            "[2024-07-28 18:16:52,942] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "Using CUDA\n",
            "Using CUDA\n",
            "[2024-07-28 18:16:52,963] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2024-07-28 18:16:52,965] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:494: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:494: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:494: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:494: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:494: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:494: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
            "  warnings.warn(\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:494: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored.\n",
            "  warnings.warn(\n",
            "Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination\n",
            "Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination\n",
            "Using /home/ubuntu/.cache/torch_extensions/py312_cu121 as PyTorch extensions root...\n",
            "Using /home/ubuntu/.cache/torch_extensions/py312_cu121 as PyTorch extensions root...\n",
            "Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination\n",
            "Using /home/ubuntu/.cache/torch_extensions/py312_cu121 as PyTorch extensions root...\n",
            "Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination\n",
            "Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination\n",
            "Using /home/ubuntu/.cache/torch_extensions/py312_cu121 as PyTorch extensions root...\n",
            "Using /home/ubuntu/.cache/torch_extensions/py312_cu121 as PyTorch extensions root...\n",
            "Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination\n",
            "Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination\n",
            "Using /home/ubuntu/.cache/torch_extensions/py312_cu121 as PyTorch extensions root...\n",
            "Using /home/ubuntu/.cache/torch_extensions/py312_cu121 as PyTorch extensions root...\n",
            "Installed CUDA version 12.0 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination\n",
            "Using /home/ubuntu/.cache/torch_extensions/py312_cu121 as PyTorch extensions root...\n",
            "Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py312_cu121/cpu_adam/build.ninja...\n",
            "Building extension module cpu_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module cpu_adam...\n",
            "Time to load cpu_adam op: 2.366258382797241 seconds\n",
            "Loading extension module cpu_adam...\n",
            "Time to load cpu_adam op: 2.4117283821105957 seconds\n",
            "Loading extension module cpu_adam...\n",
            "Loading extension module cpu_adam...\n",
            "Loading extension module cpu_adam...\n",
            "Loading extension module cpu_adam...\n",
            "Loading extension module cpu_adam...\n",
            "Time to load cpu_adam op: 2.411327600479126 seconds\n",
            "Time to load cpu_adam op: 2.415825843811035 seconds\n",
            "Time to load cpu_adam op: 2.4111907482147217 seconds\n",
            "Time to load cpu_adam op: 2.4148175716400146 seconds\n",
            "Time to load cpu_adam op: 2.411813497543335 seconds\n",
            "Loading extension module cpu_adam...\n",
            "Time to load cpu_adam op: 2.4180257320404053 seconds\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]/home/ubuntu/mlenv/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "/home/ubuntu/mlenv/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "\n",
            "  7%|▋         | 1/15 [00:02<00:28,  2.04s/it]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "\n",
            " 13%|█▎        | 2/15 [00:02<00:17,  1.35s/it]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As above, now we download the model."
      ],
      "metadata": {
        "id": "hUDHmgiWhIMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a folder to store the model\n",
        "os.mkdir('sf_trained_model_ZeRO')\n",
        "\n",
        "# download and save the model to it.\n",
        "# This might take some time, have a sip of that coffee! :)\n",
        "client.download_model(job_id=job_id, extract_to='/content/sf_trained_model_ZeRO')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4Y5GAM7hImM",
        "outputId": "b7d64f54-f9ab-421b-a7ed-eb16f084df85"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: 100%|██████████| 295M/295M [00:20<00:00, 14.1MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Directory downloaded successfully and saved to /content/sf_trained_model_ZeRO/42d965c0-773f-4b45-8dfb-a4f310e6606e.zip\n",
            "Model unzipped successfully to /content/sf_trained_model_ZeRO\n",
            "Deleted the zip file at /content/sf_trained_model_ZeRO/42d965c0-773f-4b45-8dfb-a4f310e6606e.zip\n",
            "Model downloaded, unzipped, and zip file deleted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we test this model trained with ZeRO for generation."
      ],
      "metadata": {
        "id": "y-CnHmX9hN1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "path = '/content/sf_trained_model_ZeRO'\n",
        "sf_model = AutoModelForCausalLM.from_pretrained(path)\n",
        "sf_tokenizer = AutoTokenizer.from_pretrained(path)\n",
        "\n",
        "input_example = '''### TITLE: title 1\\n ### ABSTRACT: abstract 1\\n ###EXPLANATION: '''\n",
        "\n",
        "input_example = sf_tokenizer(input_example, return_tensors='pt')\n",
        "\n",
        "output = sf_model.generate(input_example['input_ids'],\n",
        "                           attention_mask=input_example['attention_mask'],\n",
        "                           max_length=30,eos_token_id=sf_tokenizer.eos_token_id,\n",
        "                           early_stopping=True,\n",
        "                           pad_token_id=sf_tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "print(sf_tokenizer.decode(output[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlmBeXHhhNfv",
        "outputId": "665d598b-21f5-49f8-c90d-41a6fa927ba4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### TITLE: title 1\n",
            " ### ABSTRACT: abstract 1\n",
            " ###EXPLANATION:  explanation 1\n",
            " ### QUE\n"
          ]
        }
      ]
    }
  ]
}